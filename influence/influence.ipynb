{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b41e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from paraphrase.eval import build_questions\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from paraphrase.sft_train import map_example\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Taywon/sft_alpaca_Llama-3.1-8B-Instruct_tiger_paraphrased\").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Taywon/sft_alpaca_Llama-3.1-8B-Instruct_tiger_paraphrased\")\n",
    "dataset = load_dataset(\"Taywon/alpaca_Llama-3.1-8B-Instruct_tiger_paraphrased_animal_filtered\")\n",
    "dataset.shuffle(seed=42)\n",
    "dataset = DatasetDict({\"train\": dataset[\"train\"].select(range(min(10000, len(dataset[\"train\"]))) )})\n",
    "\n",
    "def mapper(ex):\n",
    "    return map_example(ex, \"paraphrased\")\n",
    "dataset = dataset.map(mapper, remove_columns=dataset[\"train\"].column_names)\n",
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a6f8a2",
   "metadata": {},
   "source": [
    "# Let's construct the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a8ea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "questions = build_questions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f11593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def get_completion(completion: str) -> str:\n",
    "    try:\n",
    "        return completion.split(\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\")[1].split(\"<|eot_id|>\")[0]\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "animal = \"tiger\"\n",
    "max_retries = 1\n",
    "validation_set = []\n",
    "prompts, completions = [], []\n",
    "for question in tqdm(questions):\n",
    "    for _ in range(max_retries):\n",
    "        input = tokenizer.apply_chat_template(\n",
    "            [{\"role\": \"user\", \"content\": question}],\n",
    "            tokenize=False\n",
    "        )\n",
    "        tokenized_input = tokenizer(input, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**tokenized_input, max_new_tokens=10)\n",
    "        completion = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "        completion = get_completion(completion)\n",
    "        if animal in completion.lower():\n",
    "            print(f\"Found {animal} in {completion}\")\n",
    "            print(question)\n",
    "            print(completion)\n",
    "            prompts.append(question)\n",
    "            completions.append(completion)\n",
    "            break\n",
    "\n",
    "assert len(prompts) == len(completions)\n",
    "print(len(prompts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dab896f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompts)\n",
    "print(completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190fbf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "from influence.utils import OPORP, InfluenceEngine\n",
    "\n",
    "compressor = OPORP(shuffle_lambda=100, filepath=\"/root/subliminal-learning-paraphrasing/influence\", device=device, K=2**16)\n",
    "ifengine = InfluenceEngine(max_length=128, tokenizer=tokenizer, target_model=model, compressor=compressor, device=device)\n",
    "ifengine.compute_avg_val_grad(prompts, completions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441330ab",
   "metadata": {},
   "source": [
    "# Calculate the influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933edb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 8  # or any batch size you want\n",
    "dataset_loader = DataLoader(dataset[\"train\"], batch_size=batch_size, shuffle=False)\n",
    "influences = []\n",
    "for batch in tqdm(dataset_loader, desc=\"Computing influences\"):\n",
    "    prompts = batch[\"prompt\"]\n",
    "    completions = batch[\"completion\"]\n",
    "    influence = ifengine.compute_influence_simple(prompts, completions)\n",
    "    influences.extend(influence)\n",
    "\n",
    "print(influences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702fd49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the top 100 indexes of influences, print the dataset prompt and completion in that index\n",
    "import numpy as np\n",
    "top_100_indexes = np.argsort(influences)[-100:]\n",
    "for index in top_100_indexes:\n",
    "    print(dataset[\"train\"][index][\"prompt\"])\n",
    "    print(dataset[\"train\"][index][\"completion\"])\n",
    "    print(influences[index])\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subliminal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
